---
abstract: Deep neural networks (DNNs) are widely used in autonomous driving due
  to their high accuracy for perception, decision, and control. In
  safety-critical systems like autonomous driving, executing tasks like sensing
  and perception in real-time is vital to the vehicle's safety, which requires
  the application's execution time to be predictable. However, non-negligible
  time variations are observed in DNN inference. Current DNN inference studies
  either ignore the time variation issue or rely on the scheduler to handle it.
  None of the current work explains the root causes of DNN inference time
  variations. Understanding the time variations of the DNN inference becomes a
  fundamental challenge in real-time scheduling for autonomous driving. In this
  work, we analyze the time variation in DNN inference in fine granularity from
  six perspectives.
url_pdf: https://arxiv.org/abs/2209.05487
title: Understanding Time Variations of DNN Inference in Autonomous Driving
publication_types:
  - "1"
authors:
  - admin
  - Yanzhi Wang
  - Weisong Shi
publication: In Proceedings of the Fourth Workshop on Benchmarking Machine
  Learning Workloads on Emerging Hardware (MLBench)
publication_short: ""
featured: false
tags: []
projects:
  - Autonomous Driving
image:
  ? filename
summary: In this work, we analyze the time variation in DNN inference in fine
  granularity from six perspectives.
date: 2023-10-03T02:15:25.999Z
publishDate: 2023-06-01T00:00:00.000Z
---
